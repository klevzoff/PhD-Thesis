\chapter{Conclusions}
\chaptermark{Conclusions}
\label{ch:conclusions}

% ===================== SECTION =====================
\section{Summary of Present Work}

This work addresses the development of a multilevel multiscale preconditioning framework for problems of geomechanics, porous media flow and coupled poromechanics on general (unstructured) polyhedral grids, with the goal of accelerating solutions of large and ill-conditioned linear systems arising in subsurface applications such as modeling of geological carbon storage, geothermal energy systems, oil and gas reservoirs and other, leading to faster simulation turnaround times without sacrificing model fidelity and improving the decision making process in these applications.   Multiscale methods both have enjoyed a lot of success as fast approximate solvers, and have been shown to be excellent candidates for efficient and scalable preconditioners for elliptic linear systems.

In \cref{ch:multiscale_poromechanics}, after briefly reviewing previous work on multiscale methods, we conclude that Multiscale Restriction-Smoothed Basis (MsRSB) is an excellent candidate for further development.   We further adapt the method to some discretizations of interest by introducing a matrix filtering strategy designed to ensure convergence of the basis function iterative computation.   The rest of the chapter deals with the development of the multiscale framework, specifically the multilevel grid representation and unstructured coarsening algorithms and construction of basis function supports for both nodal and cell-centered unknowns.  The proposed algorithms are flexible with respect to grid topology and agglomeration techniques and only require knowledge of grid connectivity structure (element-to-node maps).   We extend the method to coupled systems of equations such as single-phase poromechanics by employing a combination of block-diagonal grid transfer operators and a block-triangular local smoother.   Further extension to multiphase poromechanics is proposed based on two different reduction strategies.   Several two- and three-dimensional problems are used to validate our method and demonstrate its robustness.   The extension of MsRSB to geomechanics/poromechanics and its formulation as a truly multilevel framework suitable for arbitrary grids both constitute novel contributions of our work.

\Cref{ch:geosx_framework} describes the overall design and several key components of GEOSX, a high-performance multiphysics simulation framework developed collectively by several research groups, to which we have made several contributions, further detailed in the chapter, including a GPU-accelerated multi-component multiphase flow and transport solver and components of a linear algebra framework that interfaces with several external libraries of linear solvers and preconditioners.   The latter serves as the foundation for the parallel implementation of our multiscale method.

Finally, \cref{ch:parallel_multiscale} investigates the performance and scalability of the proposed multiscale solver in shared and distributed memory parallel settings.   To this end, we develop an optimized implementation that both reuses high-performance matrix and vector kernels from a given linear algebra backend and employs the parallel programming features of GEOSX to accelerate the construction of the multilevel hierarchy.   The implementation is used to demonstrate parallel scalability of the method and compare it to an algebraic multigrid solver.   We observe good weak and strong scaling on both modern multi-core CPU architectures and multi-node compute clusters using a series of structured and unstructured benchmark problems and find that out multiscale preconditioner is a competitive alternative to algebraic multigrid for problems of geomechanics.   This is the first performance investigation of a parallel multiscale method implementation for poromechanical problems.   This study also highlights some limitations of our implementation and suggests further improvements to the method are necessary, in particular with respect to robustness of the interpolation the flow problem.

% ===================== SECTION =====================
\section{Future Work}

There are a number of ways in which the work presented here can be continued or extended.   Here we present some promising research directions targeting both performance issues and real-world applicability of the method.

\subsection{Performance Improvements}

\begin{itemize}
  \item As highlighted in \cref{subsec:par_discussion}, our multiscale method has some deficiencies with respect to the coarsening and interpolation for the flow problem that manifest through an increase in the number of iterations in weak scaling studies (up to 2.5x growth for 64x problem refinement).   In contrast, multigrid methods have shown very limited (if any) degradation of convergence.   Additional investigation into construction of coarse spaces for pressure unknowns (in particular, strength-of-connection based coarsening) may yield significant benefit for both the flow and poromechanical problems.
  \item In addition, while we restricted our smoother choice to $\ell_1$ hybrid symmetric Gauss-Seidel based on limited experiments, it is worthwhile evaluating other smoothing options that may have less degradation in multithreaded environments, in particular of Chebyshev or multi-color Gauss-Seidel families.   Given that they have a non-trivial setup cost, an optimal setup for each must be investigated to come up with the best set of options for each problem type.
  \item Another implementation issue discussed in \cref{subsec:par_discussion} is the lack of system redistribution to a smaller number of processors at coarse levels, which is a standard technique in algebraic multigrid frameworks aimed at  reducing non-scalable work and communication overhead in the solver.   While not an issue for previously reported two-level methods, this can have a significant benefit for the parallel performance of the multilevel multiscale solver.
  \item An important continuation of present work is to investigate performance and scaling of the solver on GPU architectures.   Some studies of GPU-accelerated MsRSB solvers have recently emerged \cite{Manea2021,Manea2022}, but they have focused exclusively on Cartesian grids and scalar (flow) problems.   An unstructured grid method like the one presented here is likely to have very different performance trade-offs and optimal design choices on the GPU.   Although our implementation has been developed with support for GPU execution, a lack of certain GPU-enabled kernels in linear algebra backends has prevented us from exercising this capability.   However it is the next logical step for a framework like GEOSX that targets performance portability.
\end{itemize} 

\subsection{Method Extensions}

\begin{itemize}
  \item While this work focused on accelerating single-phase poromechanics problems, real-world applications like carbon storage require a solver capable of dealing with multiphase poromechanical systems.   In \cref{subsec:coupled_multiphase} we have outlined two possible ways of combining multiscale with CPR-based system reduction techniques.   Implementing these approaches in the solver framework in a performant way and evaluating their benefits and drawbacks is a necessary step towards making the multiscale solver a useful tool for solving large-scale subsurface problems.
  \item Similarly, we have presented some simple ideas on the handling of well equations and unknowns in \cref{subsec:coupled_wells}.   Implementation and validation of this approach is a worthwhile endeavor since most real-world problems will contain dozens, potentially hundreds of wells.   Whether or not preserving well degrees-of-freedom throughout the multilevel hierarchy is a viable option, or if more sophisticated strategies are required, remains to be seen.
  \item In addition to multiphase transport, handling of thermal problems is an important extension.   Depending on the heat transfer regime (advection- or diffusion dominated), temperature unknown may either have elliptic or hyperbolic character, necessitating the use of different solution strategies \cite{Cremon2020}.   For diffusion-dominated cases, multiscale may be an appropriate solution method for the temperature field, but it remains an open question under what conditions treating it via a three-field coupled multilevel hierarchy versus decoupling at the fine level via Schur complement would be an optimal strategy.
  \item Discontinuities (fractures and faults) play an significant role in many subsurface applications.   Extensions of multiscale methods to fractured porous media have been developed for both geomechanics \cite{Levonyan2019} and flow problems \cite{Bosma2017} in the context of MSFE method, and for MsRSB method for flow.   Properly incorporating discontinuities in MsRSB basis functions for displacement field is an interesting research question, addressing which is of great practical importance.
  
\end{itemize}